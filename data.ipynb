{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from decord import VideoReader, cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开jsonl文件\n",
    "with open('/zhaobai46d/dataset/videodata/qvhighlights/highlight_train_release.jsonl', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': 9769,\n",
       " 'query': 'some military patriots takes us through their safety procedures and measures.',\n",
       " 'duration': 150,\n",
       " 'vid': 'j7rJstUseKg_360.0_510.0',\n",
       " 'relevant_clip_ids': [36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  72],\n",
       " 'saliency_scores': [[4, 3, 2],\n",
       "  [4, 1, 3],\n",
       "  [4, 3, 4],\n",
       "  [4, 1, 2],\n",
       "  [4, 2, 2],\n",
       "  [4, 2, 2],\n",
       "  [4, 2, 2],\n",
       "  [4, 2, 2],\n",
       "  [4, 1, 2],\n",
       "  [4, 1, 3],\n",
       "  [4, 3, 4],\n",
       "  [4, 3, 3],\n",
       "  [4, 3, 3],\n",
       "  [4, 3, 4],\n",
       "  [4, 3, 2],\n",
       "  [4, 1, 2],\n",
       "  [4, 3, 2],\n",
       "  [4, 1, 2],\n",
       "  [4, 1, 2],\n",
       "  [4, 1, 2],\n",
       "  [4, 1, 2],\n",
       "  [3, 3, 3],\n",
       "  [4, 3, 4],\n",
       "  [4, 1, 3],\n",
       "  [4, 1, 2],\n",
       "  [4, 1, 2],\n",
       "  [4, 1, 2],\n",
       "  [4, 1, 2],\n",
       "  [4, 1, 2]],\n",
       " 'relevant_windows': [[72, 82],\n",
       "  [84, 94],\n",
       "  [96, 106],\n",
       "  [108, 118],\n",
       "  [120, 130],\n",
       "  [136, 142],\n",
       "  [144, 146]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    del data[i]['relevant_clip_ids']\n",
    "    del data[i]['saliency_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[72, 82], [84, 94], [96, 106], [108, 118], [120, 130], [136, 142], [144, 146]]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(data[0]['relevant_windows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "# prompt = \"Given the video and the query, find the relevant windows. Relevant windows:\"\n",
    "prompt = \"\\nTask: According to the seconds of frame and video duration, find the relevant windows of the query.\"\n",
    "addition_response = \"The relevant windows are: \"\n",
    "for item in data:\n",
    "    image_tokens = \"\"\n",
    "    fps = item['duration']\n",
    "    for i in range(1, 65, 1):\n",
    "        # 计算均匀采样64帧的秒数\n",
    "        second = int(fps / 64 * (i-1))\n",
    "        image_tokens += f\"{second}s <image {i}>\\n\"\n",
    "    new_dict = {'id': item['qid'], 'image': item['vid'] + '.mp4'}\n",
    "    human = {'from': 'human', 'value':'Video:\\n' + image_tokens + 'Video duration: ' + str(fps) + 's\\nQuery: ' + item['query'] + prompt}\n",
    "    gpt = {'from': 'gpt', 'value': str(item['relevant_windows'])}\n",
    "    conversations = []\n",
    "    conversations.append(human)\n",
    "    conversations.append(gpt)\n",
    "    new_dict['conversations'] = conversations\n",
    "    new_dict['video'] = '1'\n",
    "    new_list.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "prompt = \"Task: Caption the video.\"\n",
    "for item in data:\n",
    "    image_tokens = \"\"\n",
    "    fps = item['duration']\n",
    "    for i in range(1, 65, 1):\n",
    "        image_tokens += f\"<image {i}>\\n\"\n",
    "    new_dict = {'id': item['qid'], 'image': item['vid'] + '.mp4'}\n",
    "    human = {'from': 'human', 'value':'Video:\\n' + image_tokens + prompt}\n",
    "    gpt = {'from': 'gpt', 'value': item['query']}\n",
    "    conversations = []\n",
    "    conversations.append(human)\n",
    "    conversations.append(gpt)\n",
    "    new_dict['conversations'] = conversations\n",
    "    new_dict['video'] = '1'\n",
    "    new_list.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 9769,\n",
       " 'image': 'j7rJstUseKg_360.0_510.0.mp4',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': 'Video:\\n<image 1>\\n<image 2>\\n<image 3>\\n<image 4>\\n<image 5>\\n<image 6>\\n<image 7>\\n<image 8>\\n<image 9>\\n<image 10>\\n<image 11>\\n<image 12>\\n<image 13>\\n<image 14>\\n<image 15>\\n<image 16>\\n<image 17>\\n<image 18>\\n<image 19>\\n<image 20>\\n<image 21>\\n<image 22>\\n<image 23>\\n<image 24>\\n<image 25>\\n<image 26>\\n<image 27>\\n<image 28>\\n<image 29>\\n<image 30>\\n<image 31>\\n<image 32>\\n<image 33>\\n<image 34>\\n<image 35>\\n<image 36>\\n<image 37>\\n<image 38>\\n<image 39>\\n<image 40>\\n<image 41>\\n<image 42>\\n<image 43>\\n<image 44>\\n<image 45>\\n<image 46>\\n<image 47>\\n<image 48>\\n<image 49>\\n<image 50>\\n<image 51>\\n<image 52>\\n<image 53>\\n<image 54>\\n<image 55>\\n<image 56>\\n<image 57>\\n<image 58>\\n<image 59>\\n<image 60>\\n<image 61>\\n<image 62>\\n<image 63>\\n<image 64>\\nTask: Caption the video.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'some military patriots takes us through their safety procedures and measures.'}],\n",
       " 'video': '1'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/zhaobai46d/dataset/videodata/qvhighlights/test5.json', 'w') as f:\n",
    "    json.dump(new_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/zhaobai46d/dataset/videodata/qvhighlights/test4.json', 'r') as f:\n",
    "    ff = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 9769,\n",
       " 'image': 'j7rJstUseKg_360.0_510.0.mp4',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': 'Video:\\n0s <image 1>\\n2s <image 2>\\n4s <image 3>\\n7s <image 4>\\n9s <image 5>\\n11s <image 6>\\n14s <image 7>\\n16s <image 8>\\n18s <image 9>\\n21s <image 10>\\n23s <image 11>\\n25s <image 12>\\n28s <image 13>\\n30s <image 14>\\n32s <image 15>\\n35s <image 16>\\n37s <image 17>\\n39s <image 18>\\n42s <image 19>\\n44s <image 20>\\n46s <image 21>\\n49s <image 22>\\n51s <image 23>\\n53s <image 24>\\n56s <image 25>\\n58s <image 26>\\n60s <image 27>\\n63s <image 28>\\n65s <image 29>\\n67s <image 30>\\n70s <image 31>\\n72s <image 32>\\n75s <image 33>\\n77s <image 34>\\n79s <image 35>\\n82s <image 36>\\n84s <image 37>\\n86s <image 38>\\n89s <image 39>\\n91s <image 40>\\n93s <image 41>\\n96s <image 42>\\n98s <image 43>\\n100s <image 44>\\n103s <image 45>\\n105s <image 46>\\n107s <image 47>\\n110s <image 48>\\n112s <image 49>\\n114s <image 50>\\n117s <image 51>\\n119s <image 52>\\n121s <image 53>\\n124s <image 54>\\n126s <image 55>\\n128s <image 56>\\n131s <image 57>\\n133s <image 58>\\n135s <image 59>\\n138s <image 60>\\n140s <image 61>\\n142s <image 62>\\n145s <image 63>\\n147s <image 64>\\nVideo duration: 150s\\nQuery: some military patriots takes us through their safety procedures and measures.\\nTask: According to the seconds of frame and video duration, find the relevant windows of the query.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': '[[72, 82], [84, 94], [96, 106], [108, 118], [120, 130], [136, 142], [144, 146]]'}],\n",
       " 'video': '1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ff)):\n",
    "    ff[i]['image'] = ff[i]['image'].split('/')[-2] + '/' + ff[i]['image'].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '14486',\n",
       " 'image': 'lhkyt50sfCw_01110_01125.mp4/lhkyt50sfCw_01110_01125.mp4',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image 1>\\n<image 2>\\n<image 3>\\n<image 4>\\n<image 5>\\n<image 6>\\n<image 7>\\n<image 8>\\nSummarize the video in a sentence, taking into account the text and its relationship to the visual elements.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'There are 29 players ALIVE in the shooting game.'}],\n",
       " 'video': '1'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频总时长: 21.09秒\n"
     ]
    }
   ],
   "source": [
    "vr = VideoReader('/zhaobai46d/videobunny/video2.mp4', ctx=cpu(0), num_threads=1)\n",
    "max_frame = len(vr) - 1\n",
    "fps = float(vr.get_avg_fps())\n",
    "\n",
    "# 计算视频时长（以秒为单位）\n",
    "total_duration = (max_frame + 1) / fps\n",
    "\n",
    "print(f\"视频总时长: {total_duration:.2f}秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/zhaobai46d/small_games.json', 'w') as f:\n",
    "    json.dump(ff, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bunny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
